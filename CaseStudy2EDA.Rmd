---
title: "CaseStudy2DDS"
author: "Rinku Lichti"
date: "11/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Install and Load Libraries as needed
library(pacman)
p_load("summarytools", "dplyr", "ggplot2", "ggsci", "caret", "corrplot", "GGally", "pROC", "readr",
       "randomForestExplainer")
```

# Load the data

```{r  eruptions, echo=FALSE}
df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
```

# Summarize the raw data

```{r}
print(dfSummary(df, graph.magnif = 0.75), method = 'browser')
```

From dfSummary, I can see: 
* Age is normally distributed
* These are right skewed: DistanceFromHome, MonthlyIncome, PercentSalaryHike, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, and YearsWithCurrManager.
* These have static values: Over18, StandardHours, EmployeeCount
* ID is likely not helpful for prediction, but may be helpful for investigation


```{r}
clean.for.eda <- function(dirty) {
  dfTemp <- dirty
  
  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp <- dfTemp %>% relocate(Attrition, .after = last_col())

  dfTemp
}

df <- clean.for.eda(df)
```


```{r}
str(df)
```

# Visualize Attrition

## Attrition Distribution

```{r}
table(df$Attrition)
```

Attrition records represent a small minority of the people represented in this data.

## Attrition Bar Plot By Age

```{r}
ggplot(df) + 
  geom_histogram(mapping = aes(x=Age, fill=Attrition)) + 
  ggtitle("Distribution of Attrition by Age") + 
  scale_fill_jco() +
  ggtitle("Attrition by Age")
```

```{r}
# Helper function to plot attrition rate by anything...
plot_attrition_rate_by <- function(data, column) {
  dfTemp <- data %>%
  group_by_(column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}
```



```{r warning=F, message=F}
plot_attrition_rate_by(df, "Age")
```

```{r}
df.age_eda <- df %>%
  group_by(age_group) %>%
  count(Attrition) %>%
  mutate(age_group_attr = n/sum(n)) %>%
  filter(Attrition == "Yes")

ggplot(df.age_eda, aes(x=age_group, y=age_group_attr, group=1)) +
  geom_line(size=1) +
  geom_point(size=2) + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Attrition Rate by Age Group") + 
  ylab("Attrition Rate")
```

## DistanceFromHome

```{r warning=F, message=F}
plot_attrition_rate_by(df, "DistanceFromHome")
```
## JobSatisfaction

```{r  warning=F, message=F}
plot_attrition_rate_by(df, "JobSatisfaction")
```

## JobLevel

```{r warning=F, message=F}
plot_attrition_rate_by(df, "JobLevel")
```
## JobInvolvement

```{r warning=F, message=F}
plot_attrition_rate_by(df, "JobInvolvement")
```

## NumCompaniesWorked

```{r warning=F, message=F}
plot_attrition_rate_by(df, "NumCompaniesWorked")
```

## PercentSalaryHike

```{r warning=F, message=F}
plot_attrition_rate_by(df, "PercentSalaryHike")
```
## TrainingTimesLastYear

```{r warning=F, message=F}
plot_attrition_rate_by(df, "TrainingTimesLastYear")
```

## WorkLifeBalance

```{r warning=F, message=F}
plot_attrition_rate_by(df, "WorkLifeBalance")
```

## YearsAtCompany

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsAtCompany")
```
## YearsInCurrentRole

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsInCurrentRole")
```

## YearsSinceLastPromotion

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsSinceLastPromotion")
```
## YearsWithCurrManager

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsWithCurrManager")
```

## Compensation

```{r}
plot_attrition_rate_by(df, "HourlyRate")
plot_attrition_rate_and_facet_by(df, "HourlyRate", "OverTime")
plot_attrition_rate_by(df, "MonthlyRate")
plot_attrition_rate_by(df, "DailyRate")
plot_attrition_rate_by(df, "MonthlyIncome")
```


## Overtime

```{r warning=F, message=F}
plot_attrition_rate_by(df, "OverTime")
```

Attrition is significantly higher for those with OverTime

## JobRole

```{r warning=F, message=F}
plot_attrition_rate_hbar_by <- function(data, column) {
  dfTemp <- data %>%
    group_by_(column) %>%
    count(Attrition) %>%
    mutate(AttritionRate = n/sum(n)) %>%
    filter(Attrition == "Yes")
  dfTemp <- dfTemp %>%
    arrange(desc(AttritionRate))

  ggplot(dfTemp, aes_string(x=paste0("reorder(",column,", AttritionRate)"), y="AttritionRate")) +
    geom_col() +
    coord_flip() + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}


plot_attrition_rate_hbar_by(df, "JobRole")
```

```{r}
dfTemp <- df
dfTemp$JobSatisfactionF = as.factor(df$JobSatisfaction)

dfTemp <- dfTemp %>%
    group_by(JobRole) %>%
    count(JobSatisfaction) %>%
    mutate(JobSatisfactionPerc = n/sum(n))

ggplot(dfTemp, aes(fill=as.factor(JobSatisfaction), y=JobSatisfactionPerc, x=JobRole)) + 
  geom_bar(position="dodge", stat="identity") + 
  coord_flip() + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Job Satisfaction as a % of people in each Job Role")
```



## JobRole by Age

```{r warning=F, message=F}
plot_attrition_rate_and_facet_by <- function(data, column, facet_column) {
  dfTemp <- data %>%
  group_by_(column, facet_column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    facet_wrap(facet_column) + 
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}

plot_attrition_rate_and_facet_by(df, "Age", "JobRole")
```

# Checking for correlation

```{r warning=F, message=F}
# Look for high correlation

# Only look at numeric fields, and omit ones with constant values
dfTemp <- dfTemp %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount, -ID))
df.numeric <- dfTemp[, sapply(dfTemp, is.numeric)]
df.without_na <- na.omit(df.numeric)

corrs = cor(df.without_na) # Calculate correlations between all variables
high_corrs = findCorrelation(corrs, cutoff=0.5)
corrs = cor(df.without_na[,high_corrs]) # get a data frame with only highly correlated variables

#Create corrplot for numeric variables
corrplot(corrs)
```

While there are some intuitive correlations, such as YearsAtCompany and YearsWithCurrentManager, I don't see why we should exclude any of these, which may contribute unique value.


```{r warning=F, message=F}
ggpairs(df.without_na[,high_corrs])
```


# T-test to compare each group
Because both distrubitions differ significantly from normality we log tranform them in order to do a t-test and see if there is evidence that the distributions differ significantly from each other. 

The QQ Plot of the log transformed MonthlyIncome for each group shows much better adherence to normality, and brings the variance of each group much closer together. 

The T-test itself shows there is a significant difference between the Monthly Incomes of "Yes" vs "No" attrition groups, p-value < 0.0001. This is strong evidence that MonthlyIncome has an effect on Attrition


```{r}
# make vectors for monthly income by attrition
#emp_clean.df$MonthlyIncome[emp_clean.df$Attrition == "Yes"] -> mo_income_yes
#emp_clean.df$MonthlyIncome[emp_clean.df$Attrition == "No"] -> mo_income_no
# number of yes vs no attrition
# length(mo_income_yes)
# length(mo_income_no)
# summary(mo_income_yes) 
# summary(mo_income_no) 
# sd(mo_income_yes) 
# sd(mo_income_no) 
# # histogram of each
# hist(mo_income_yes, xlab = "Dollars", main = "Salary for Attrition: Yes")
# hist(mo_income_no, xlab = "Dollars", main = "Salary for Attrition: No")
# 
# # taking log of each
# qqnorm(log(mo_income_yes))
# qqnorm(log(mo_income_no))
# # even using the log of both still get 
# # to be safe we account for unequal variance
# t.test(log(mo_income_no), log(mo_income_yes), var.equal = F) 

```


# Identify the top factors contributing to Monthly Income

```{r}
set.seed(1234)
RFcontrol <- rfeControl(
  functions=rfFuncs, 
  method="cv", 
  number=5, 
  verbose = FALSE)

sizes <- c(1:5, 10, 15, 20)

dfTemp <- df %>% relocate(MonthlyIncome, .after = last_col())

RFresults <- rfe(dfTemp[,1:(ncol(dfTemp)-1)], 
                 dfTemp[[ncol(dfTemp)]], 
                 sizes=sizes, 
                 rfeControl=RFcontrol)

RFresults
varImp(RFresults)
```

For MonthlyIncome, the top factors are JobLevel, JobRole, and TotalWorkingYears

## Looking more at JobLevel and MonthlyIncome

```{r}
qqplot(factor(df$JobLevel), df$MonthlyIncome)

ggplot(df, mapping = aes(x = MonthlyIncome, color = factor(JobLevel), fill = factor(JobLevel))) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(factor(df$JobLevel)) + 
  scale_color_jco() +
  scale_fill_jco()
```

It looks like there is a linear relationship between JobLevel and MonthlyIncome, and the respective MonthlyIncome ranges are somewhat normal.

## Looking more at JobRole and MonthlyIncome

```{r}
qqplot(df$JobRole, df$MonthlyIncome)

ggplot(df, mapping = aes(x = MonthlyIncome, color = JobRole, fill = JobRole)) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(df$JobRole) + 
  scale_color_jco() +
  scale_fill_jco()

```
It looks like there is a relationship, though non-linear. Also the roles to be are: Research Director and Manager.  I'll run with Research Director. 


## Looking more at TotalWorkingYears and MonthlyIncome

```{r}
qqplot(factor(df$TotalWorkingYears), df$MonthlyIncome)

dfTemp <- df %>% filter(TotalWorkingYears < 10)
ggplot(dfTemp, mapping = aes(x = MonthlyIncome, color = factor(TotalWorkingYears), fill = factor(TotalWorkingYears))) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(factor(dfTemp$TotalWorkingYears)) + 
  scale_color_jco() +
  scale_fill_jco()
```
It looks like TotalWorkingYears has a linear relationship with MonthlyIncome.

# Near Zero Variance

```{r}
nzv <- nearZeroVar(df, saveMetrics = T)
nrow(nzv %>% filter(nzv == TRUE))
```

No variables are near zero variance

# Identify the top factors contributing to Attrition

```{r}
set.seed(1234)
RFcontrol <- rfeControl(
  functions=rfFuncs, 
  method="cv", 
  number=5, 
  verbose = FALSE)

sizes <- c(1:5, 10, 15, 20)

RFresults <- rfe(df[,1:(ncol(df)-1)], 
                 df[[ncol(df)]], 
                 sizes=sizes, 
                 rfeControl=RFcontrol)

RFresults
varImp(RFresults)
```

The Top factors that contribute to turnover are:
1. OverTime

# Clean/Train/Test Split

```{r}
# - Load and Clean for MonthlyIncome

clean.for.modeling.monthly_income <- function(dirty) {
  dfTemp <- dirty %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount, -Attrition))

  #TODO: log these: DistanceFromHome, MonthlyIncome, PercentSalaryHike, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, and YearsWithCurrManager
  
  dfTemp
}

load.and.clean.for.monthly_income <- function() {
  df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
  df <- clean.for.modeling.monthly_income(df)
  
  df <- df %>% dplyr::select(c(-ID))
  df <- df %>% relocate(MonthlyIncome, .after = last_col())
}

df <- load.and.clean.for.monthly_income()

set.seed(1234)
num_rows <- nrow(df)
train_idx <- sample(1:num_rows, 0.8 * num_rows)
test_idx <- setdiff(1:num_rows, train_idx)
mi.train <- df[train_idx, ]
mi.test <- df[test_idx, ]

# - Load and Clean for Attrition

clean.for.modeling.attrition <- function(dirty) {
  dfTemp <- dirty %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount))

  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp
}

load.and.clean.for.attrition <- function() {
  df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
  df <- clean.for.modeling.attrition(df)
  
  df <- df %>% dplyr::select(c(-ID))
  df <- df %>% relocate(Attrition, .after = last_col())
}

df <- load.and.clean.for.attrition()

set.seed(1234)
num_rows <- nrow(df)
train_idx <- sample(1:num_rows, 0.8 * num_rows)
test_idx <- setdiff(1:num_rows, train_idx)
at.train <- df[train_idx, ]
at.test <- df[test_idx, ]
```

# MonthlyIncome Models

## Linear Regression

```{r}
lr_control <- trainControl(method = "cv", num = 5)

mi.fitLR <- train(MonthlyIncome ~ ., 
               data = mi.train, 
               method = "glm", 
               trControl = lr_control
               )
mi.fitLR
```

```{r}
summary(mi.fitLR)
```

It's sad that Age is negatively correlated with MonthlyIncome.  But not as negatively as working in Human Resources. Or being Single.  Ouch.

```{r}
test.MonthlyIncome_LR <- predict(mi.fitLR, newdata = mi.test)
mi.fitLR.RMSE <- RMSE(test.MonthlyIncome_LR, mi.test$MonthlyIncome)
mi.fitLR.RMSE
RMSE(test.MonthlyIncome_LR, mi.test$MonthlyIncome) / mean(mi.test$MonthlyIncome)
```

This model is performing well within the $3,000 goal, so moving on to...

## Random Forest

### Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     num = 5)

mi.fitRF <- train(MonthlyIncome ~ ., 
               data = mi.train, 
               method = "ranger", 
               importance = "impurity",
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100
               )
mi.fitRF
```

### Performance on Training Set

```{r}
summary(mi.fitRF)
plot(mi.fitRF)
```

```{r}
test.MonthlyIncome_RF <- predict(mi.fitRF, newdata = mi.test)
mi.fitRF.RMSE <- RMSE(test.MonthlyIncome_RF, mi.test$MonthlyIncome)
mi.fitRF.RMSE
RMSE(test.MonthlyIncome_RF, mi.test$MonthlyIncome) / mean(mi.test$MonthlyIncome)
```

### Min Depth Distribution

```{r}
mi.forest_frame <- min_depth_distribution(mi.fitRF$finalModel)
plot_min_depth_distribution(mi.forest_frame)
```

### Mean minimal depth for most frequent interactions

```{r echo=F, warning=F, message=F}
plot_min_depth_interactions(mi.fitRF$finalModel, k=7)
```

```{r echo=F, message=F}
multi_imps = measure_importance(mi.fitRF$finalModel)
plot_importance_ggpairs(multi_imps)
```

## Comparing MonthlyIncome Models

```{r}
mi.compare <- data.frame(model = c("Linear Regression", "Random Forest"), RMSE = c(mi.fitLR.RMSE, mi.fitRF.RMSE))
mi.compare
```

Both models perform well below the $3,000 RMSE threshold for this case study. Since Random Forest has slightly lower RMSE, Random Forest wins.


```{r}
mi.winner <- mi.fitRF
```


# Attrition

## KNN

For KNN, I'm optimizing for Kappa, which is more appropriate for imbalanced classes

```{r}
set.seed(12)
cv_control <- trainControl(
  method="repeatedcv",
  repeats = 3, 
  number = 5,
  classProbs = TRUE,
  savePredictions = TRUE,
  )

at.fitKNN <- train(Attrition ~ ., 
               data = at.train, 
               method = "knn", 
               metric = "Kappa",
               trControl = cv_control,
               preProcess = c("center","scale"),
#               tuneLength=20
               tuneGrid = expand.grid(k = c(1:5, 10, 20))
               )  
at.fitKNN
```

```{r}
plot(at.fitKNN)
confusionMatrix(at.fitKNN)
```

```{r}
at.fitKNN.predictions.raw <- predict(at.fitKNN, newdata = at.test, type="raw")
at.fitKNN.predictions.prob <- predict(at.fitKNN, newdata = at.test, type="prob")
confusionMatrix(at.fitKNN.predictions.raw, at.test$Attrition, positive="Yes")
```

```{r warning=F, message=F}
at.prediction.probabilities <- at.fitKNN.predictions.prob$Yes
at.predicted.classes <- at.fitKNN.predictions.raw
at.observed.classes <- at.test$Attrition

at.res.roc <- roc(at.observed.classes, at.prediction.probabilities)
plot.roc(at.res.roc, print.auc = TRUE, print.thres = "best")
```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
cutoff <- coords(at.res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
at.predicted.classes.balanced <- factor(
  ifelse( at.fitKNN.predictions.prob$Yes > cutoff, "Yes", "No"), levels=c("No","Yes"))
at.fitKNN.cm <- confusionMatrix(at.predicted.classes.balanced, at.test$Attrition, positive="Yes")
at.fitKNN.cm
```



# Random Forest

# Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     classProbs = TRUE,
                     savePredictions = TRUE,
                     summaryFunction = twoClassSummary,
                     num = 5)

rf_grid <- expand.grid(
  mtry = 6:12,
  splitrule = c("gini","extratrees", "hellinger"),
  min.node.size = c(1)
)

at.fitRF <- train(Attrition ~ ., 
               data = at.train, 
               method = "ranger", 
               metric = "ROC",
               importance = "impurity",
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100,
               tuneGrid=rf_grid)  
at.fitRF
```

# Performance on Training Set

```{r}
plot(at.fitRF)
confusionMatrix(at.fitRF)
```

## Min Depth Distribution

```{r}
at.forest_frame <- min_depth_distribution(at.fitRF$finalModel)
plot_min_depth_distribution(at.forest_frame)
```
Overtime is clearly the most influential variable on its own, but let's look at interactions...

### Mean minimal depth for most frequent interactions

```{r echo=F, warning=F, message=F}
plot_min_depth_interactions(at.fitRF$finalModel, k=7)
```

An interesting observation is that HourlyRate on its own is one of the less influential variables, but when combined with OverTimeYes, it becomes the most influential interaction. 

### Other measures of importance

```{r echo=F, message=F}
at.multi_imps = measure_importance(at.fitRF$finalModel)
plot_importance_ggpairs(at.multi_imps)
```

# Performance on Test Set

```{r}
at.fitRF.predictions.raw <- predict(at.fitRF, newdata = at.test, type="raw")
at.fitRF.predictions.prob <- predict(at.fitRF, newdata = at.test, type="prob")
confusionMatrix(at.fitRF.predictions.raw, at.test$Attrition, positive="Yes")
```

# ROC Curve and Optimal Cutoff

```{r warning=F, message=F}
at.prediction.probabilities <- at.fitRF.predictions.prob$Yes
at.predicted.classes <- at.fitRF.predictions.raw
at.observed.classes <- at.test$Attrition

# Compute roc
at.res.roc <- roc(at.observed.classes, at.prediction.probabilities)
plot.roc(at.res.roc, print.auc = TRUE, print.thres = "best")
```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
at.cutoff.randomforest <- coords(at.res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
at.predicted.classes.balanced <- factor(
  ifelse( at.fitRF.predictions.prob$Yes > cutoff.randomforest, "Yes", "No"), levels=c("No","Yes"))
at.fitRF.cm <- confusionMatrix(at.predicted.classes.balanced, at.test$Attrition, positive="Yes")
at.fitRF.cm
```


# Accuracy Model Comparison

```{r}
atModel <- c("KNN", "Random Forest")
atAccuracy <- c(at.fitKNN.cm$overall['Accuracy'], at.fitRF.cm$overall['Accuracy'])
atKappa <- c(at.fitKNN.cm$overall['Kappa'], at.fitRF.cm$overall['Kappa'])
atSensitivity <- c(at.fitKNN.cm$byClass['Sensitivity'], at.fitRF.cm$byClass['Sensitivity'])
atSpecificity <- c(at.fitKNN.cm$byClass['Specificity'], at.fitRF.cm$byClass['Specificity'])
at.compare <- data.frame(atModel, atAccuracy, atKappa, atSensitivity, atSpecificity)
at.compare
```

KNN is overall more accurate, but Random Forest has slightly higher Kappa and more Sensitivity, while being a bit less Specific. Also, KNN dipped below 60 on Sensitivity, so for the purposes of this case study, which requires both Sensitivity and Specificity to be more than 60, Random Forest wins.

```{r}
at.winner <- at.fitRF
at.winner.cutoff <- at.cutoff.randomforest
```


# Comp Set: No Attrition

## Load the No Attrition comp set and clean it the same way we did for modeling

```{r}
dfNoAttrition <- read.csv("doc/CaseStudy2CompSet No Attrition.csv", stringsAsFactors=TRUE)
dfNoAttrition <- clean.for.modeling(dfNoAttrition)
```

## Predict Attrition using our best model from the training above

```{r}
# Use the best model to get predicted probabilities for each class
dfNoAttrition.predictions.prob <- predict(at.winner, newdata = dfNoAttrition, type="prob")

# Use the most balanced cutoff on the predicted probabilities to get the Attrition values
dfNoAttrition.predictions.class <- factor(
  ifelse( dfNoAttrition.predictions.prob$Yes > at.winner.cutoff, "Yes", "No"), levels=c("No","Yes"))
```

## Save

```{r}
dfNoAttritionSubmission <- data.frame(ID = dfNoAttrition$ID, Attrition = dfNoAttrition.predictions.class)
write.csv(dfNoAttritionSubmission, "Case2PredictionsLichti Attrition.csv")
```

# Comp Set: No Salary

## Load the No Salary comp set and clean it the same way we did for modeling

```{r}
dfNoSalary <- read.csv("doc/CaseStudy2CompSet No Salary.csv", stringsAsFactors=TRUE)
dfNoSalary <- clean.for.modeling(dfNoSalary)
```

## Predict Salary

```{r}
dfNoSalary$MonthlyIncome <- predict(mi.winner, newdata = dfNoSalary)
```


## Save

```{r}
dfNoSalarySubmission <- data.frame(ID = dfNoSalary$ID, MonthlyIncome = dfNoSalary$MonthlyIncome)
write.csv(dfNoSalarySubmission, "Case2PredictionsLichti Salary.csv")
```


