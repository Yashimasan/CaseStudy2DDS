---
title: "CaseStudy2DDS"
author: "Rinku Lichti"
date: "11/25/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Install and Load Libraries as needed
library(pacman)
p_load("summarytools", "dplyr", "ggplot2", "ggsci", "caret", "corrplot", "GGally", "pROC", "readr",
       "randomForestExplainer", "cowplot")
```

# Load the data

```{r  eruptions, echo=FALSE}
df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
```

# Summarize the raw data

```{r}
#print(dfSummary(df, graph.magnif = 0.75), method = 'browser')
```

From dfSummary, I can see: 
* Age is normally distributed
* These are right skewed: DistanceFromHome, MonthlyIncome, PercentSalaryHike, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, and YearsWithCurrManager.
* These have static values: Over18, StandardHours, EmployeeCount
* ID is likely not helpful for prediction, but may be helpful for investigation


```{r}
clean.for.eda <- function(dirty) {
  dfTemp <- dirty
  
  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp <- dfTemp %>% relocate(Attrition, .after = last_col())

  dfTemp
}

df <- clean.for.eda(df)
```


```{r}
str(df)
```

# Visualize Attrition

## Attrition Distribution

```{r}
table(df$Attrition)
```

Attrition records represent a small minority of the people represented in this data.

## Attrition Bar Plot By Age

```{r}
ggplot(df) + 
  geom_histogram(mapping = aes(x=Age, fill=Attrition)) + 
  ggtitle("Distribution of Attrition by Age") + 
  scale_fill_jco() +
  ggtitle("Attrition by Age")
```

```{r}
# Helper function to plot attrition rate by anything...
plot_attrition_rate_by <- function(data, column) {
  dfTemp <- data %>%
  group_by_(column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}
```



```{r warning=F, message=F}
trend1 <- plot_attrition_rate_by(df, "Age")
trend1
```

```{r}
df.age_eda <- df %>%
  group_by(age_group) %>%
  count(Attrition) %>%
  mutate(age_group_attr = n/sum(n)) %>%
  filter(Attrition == "Yes")

ggplot(df.age_eda, aes(x=age_group, y=age_group_attr, group=1)) +
  geom_line(size=1) +
  geom_point(size=2) + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Attrition Rate by Age Group") + 
  ylab("Attrition Rate")
```

## DistanceFromHome

```{r warning=F, message=F}
plot_attrition_rate_by(df, "DistanceFromHome")
```
## JobSatisfaction

```{r  warning=F, message=F}
trend2 <- plot_attrition_rate_by(df, "JobSatisfaction")
trend2
```

## JobLevel

```{r warning=F, message=F}
trend3 <- plot_attrition_rate_by(df, "JobLevel")
trend3
```
## JobInvolvement

```{r warning=F, message=F}
trend4 <- plot_attrition_rate_by(df, "JobInvolvement")
trend4
```

## NumCompaniesWorked

```{r warning=F, message=F}
trend5 <- plot_attrition_rate_by(df, "NumCompaniesWorked")
trend5
```

## PercentSalaryHike

```{r warning=F, message=F}
trend6 <- plot_attrition_rate_by(df, "PercentSalaryHike")
trend6
```
## TrainingTimesLastYear

```{r warning=F, message=F}
trend7 <- plot_attrition_rate_by(df, "TrainingTimesLastYear")
trend7
```

## WorkLifeBalance

```{r warning=F, message=F}
trend8 <- plot_attrition_rate_by(df, "WorkLifeBalance")
trend8
```

## YearsAtCompany

```{r warning=F, message=F}
trend9 <- plot_attrition_rate_by(df, "YearsAtCompany")
trend9
```
## YearsInCurrentRole

```{r warning=F, message=F}
trend10 <- plot_attrition_rate_by(df, "YearsInCurrentRole")
trend10
```

## YearsSinceLastPromotion

```{r warning=F, message=F}
trend11 <- plot_attrition_rate_by(df, "YearsSinceLastPromotion")
trend11
```
## YearsWithCurrManager

```{r warning=F, message=F}
trend12 <- plot_attrition_rate_by(df, "YearsWithCurrManager")
trend12
```

## Compensation

```{r}
plot_attrition_rate_by(df, "HourlyRate")
plot_attrition_rate_by(df, "MonthlyRate")
plot_attrition_rate_by(df, "DailyRate")
plot_attrition_rate_by(df, "MonthlyIncome")
```

## Trends Grid

```{r}
trends <- plot_grid(trend1, trend2, trend3, trend4, trend5, trend6, trend7, trend8, 
                    trend9, trend10, trend11, trend12, ncol = 3, labels = "auto")

trends
```



## Overtime

```{r warning=F, message=F}
plot_attrition_rate_by(df, "OverTime")
```

Attrition is significantly higher for those with OverTime

## JobRole

```{r warning=F, message=F}
plot_attrition_rate_hbar_by <- function(data, column) {
  dfTemp <- data %>%
    group_by_(column) %>%
    count(Attrition) %>%
    mutate(AttritionRate = n/sum(n)) %>%
    filter(Attrition == "Yes")
  dfTemp <- dfTemp %>%
    arrange(desc(AttritionRate))

  ggplot(dfTemp, aes_string(x=paste0("reorder(",column,", AttritionRate)"), y="AttritionRate")) +
    geom_col() +
    coord_flip() + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}


plot_attrition_rate_hbar_by(df, "JobRole")
```

```{r}
dfTemp <- df
dfTemp$JobSatisfactionF = as.factor(df$JobSatisfaction)

dfTemp <- dfTemp %>%
    group_by(JobRole) %>%
    count(JobSatisfaction) %>%
    mutate(JobSatisfactionPerc = n/sum(n))

ggplot(dfTemp, aes(fill=as.factor(JobSatisfaction), y=JobSatisfactionPerc, x=JobRole)) + 
  geom_bar(position="dodge", stat="identity") + 
  coord_flip() + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Job Satisfaction as a % of people in each Job Role")
```



## JobRole by Age

```{r warning=F, message=F}
plot_attrition_rate_and_facet_by <- function(data, column, facet_column) {
  dfTemp <- data %>%
  group_by_(column, facet_column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    facet_wrap(facet_column) + 
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}

plot_attrition_rate_and_facet_by(df, "Age", "JobRole")
```

# Checking for correlation

```{r warning=F, message=F}
# Look for high correlation

# Only look at numeric fields, and omit ones with constant values
dfTemp <- df %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount, -ID))
df.numeric <- dfTemp[, sapply(dfTemp, is.numeric)]
df.without_na <- na.omit(df.numeric)

corrs = cor(df.without_na) # Calculate correlations between all variables
high_corrs = findCorrelation(corrs, cutoff=0.5)
corrs = cor(df.without_na[,high_corrs]) # get a data frame with only highly correlated variables

#Create corrplot for numeric variables
corrplot(corrs)
```

While there are some intuitive correlations, such as YearsAtCompany and YearsWithCurrentManager, I don't see why we should exclude any of these, which may contribute unique value.


```{r warning=F, message=F}
ggpairs(df.without_na[,high_corrs])
```

# Identify the top factors contributing to Monthly Income

```{r}
set.seed(1234)
RFcontrol <- rfeControl(
  functions=rfFuncs, 
  method="cv", 
  number=5, 
  verbose = FALSE)

sizes <- c(1:5, 10, 15, 20)

dfTemp <- df %>% relocate(MonthlyIncome, .after = last_col())

RFresults <- rfe(dfTemp[,1:(ncol(dfTemp)-1)], 
                 dfTemp[[ncol(dfTemp)]], 
                 sizes=sizes, 
                 rfeControl=RFcontrol)

RFresults
varImp(RFresults)
```

For MonthlyIncome, the top factors are JobLevel, JobRole, and TotalWorkingYears


```{r}
dfTemp <- df %>% select(MonthlyIncome, JobLevel, JobRole, TotalWorkingYears)
ggpairs(dfTemp)
```


## Looking more at JobLevel and MonthlyIncome

```{r}
qqplot(factor(df$JobLevel), df$MonthlyIncome)

ggplot(df, mapping = aes(x = MonthlyIncome, color = factor(JobLevel), fill = factor(JobLevel))) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(factor(df$JobLevel)) + 
  scale_color_jco() +
  scale_fill_jco()
```

It looks like there is a linear relationship between JobLevel and MonthlyIncome, and the respective MonthlyIncome ranges are somewhat normal.

## Looking more at JobRole and MonthlyIncome

```{r}
qqplot(df$JobRole, df$MonthlyIncome)

ggplot(df, mapping = aes(x = MonthlyIncome, color = JobRole, fill = JobRole)) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(df$JobRole) + 
  scale_color_jco() +
  scale_fill_jco()

```
It looks like there is a relationship, though non-linear. Also the roles to be are: Research Director and Manager.  I'll run with Research Director. 


## Looking more at TotalWorkingYears and MonthlyIncome

```{r}
qqplot(factor(df$TotalWorkingYears), df$MonthlyIncome)

dfTemp <- df %>% filter(TotalWorkingYears < 10)
ggplot(dfTemp, mapping = aes(x = MonthlyIncome, color = factor(TotalWorkingYears), fill = factor(TotalWorkingYears))) + 
  geom_histogram(aes(x = MonthlyIncome)) +
  facet_wrap(factor(dfTemp$TotalWorkingYears)) + 
  scale_color_jco() +
  scale_fill_jco()
```
It looks like TotalWorkingYears has a linear relationship with MonthlyIncome.

# Near Zero Variance

```{r}
nzv <- nearZeroVar(df, saveMetrics = T)
nrow(nzv %>% filter(nzv == TRUE))
```

No variables are near zero variance

# Identify the top factors contributing to Attrition

```{r}
set.seed(1234)
RFcontrol <- rfeControl(
  functions=rfFuncs, 
  method="cv", 
  number=5, 
  verbose = FALSE)

sizes <- c(1:5, 10, 15, 20)

RFresults <- rfe(df[,1:(ncol(df)-1)], 
                 df[[ncol(df)]], 
                 sizes=sizes, 
                 rfeControl=RFcontrol)

RFresults
varImp(RFresults)
```


```{r}
dfTemp <- df %>% select(Attrition, JobRole, JobInvolvement, MonthlyIncome, StockOptionLevel, JobLevel)
x <- ggpairs(dfTemp)
```



# Clean/Train/Test Split

```{r}
# - Load and Clean for MonthlyIncome

clean.for.modeling.monthly_income <- function(dirty) {
  dfTemp <- dirty %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount, -Attrition))
  dfTemp
}

load.and.clean.for.monthly_income <- function(filename, removeID = TRUE) {
  df <- read.csv(filename, stringsAsFactors=TRUE)
  df <- clean.for.modeling.monthly_income(df)
  
  if (removeID) {
    df <- df %>% dplyr::select(c(-ID))
  }
  if ("MonthlyIncome" %in% names(df)) {
    df <- df %>% relocate(MonthlyIncome, .after = last_col())
  }
  df
}

df <- load.and.clean.for.monthly_income("doc/CaseStudy2-data.csv", TRUE)

set.seed(1234)
num_rows <- nrow(df)
train_idx <- sample(1:num_rows, 0.8 * num_rows)
test_idx <- setdiff(1:num_rows, train_idx)
mi.train <- df[train_idx, ]
mi.test <- df[test_idx, ]

# - Load and Clean for Attrition

clean.for.modeling.attrition <- function(dirty) {
  dfTemp <- dirty %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount))

  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp
}

load.and.clean.for.attrition <- function(filename, removeID = TRUE) {
  df <- read.csv(filename, stringsAsFactors=TRUE)
  df <- clean.for.modeling.attrition(df)
  
  if (removeID) {
    df <- df %>% dplyr::select(c(-ID))
  }
  if ("Attrition" %in% names(df)) {
    df <- df %>% relocate(Attrition, .after = last_col())
  }
  df
}

df <- load.and.clean.for.attrition("doc/CaseStudy2-data.csv", TRUE)

set.seed(1234)
num_rows <- nrow(df)
train_idx <- sample(1:num_rows, 0.8 * num_rows)
test_idx <- setdiff(1:num_rows, train_idx)
at.train <- df[train_idx, ]
at.test <- df[test_idx, ]
```

# MonthlyIncome Models

## Linear Regression

```{r}
lr_control <- trainControl(method = "cv", num = 5)

mi.fitLR <- train(MonthlyIncome ~ ., 
               data = mi.train, 
               method = "glm", 
               trControl = lr_control
               )
mi.fitLR
```

```{r}
summary(mi.fitLR)
```

It's sad that Age is negatively correlated with MonthlyIncome.  But not as negatively as working in Human Resources. Or being Single.  Ouch.

```{r}
plot(mi.fitLR$finalModel, 1)
plot(mi.fitLR$finalModel, 2)
plot(mi.fitLR$finalModel, 3)
plot(mi.fitLR$finalModel, 4)
qplot(mi.fitLR$finalModel$residuals,
      geom = "histogram",
      bins = 30) +
      labs(title = "Histogram of residuals",
      x = "residual")

#plot_grid(p1, p2, p3, p4, p5, ncol = 2, labels = "auto")
```


### RMSE for Test data

```{r}
test.MonthlyIncome_LR <- predict(mi.fitLR, newdata = mi.test)
mi.fitLR.RMSE <- RMSE(test.MonthlyIncome_LR, mi.test$MonthlyIncome)
mi.fitLR.RMSE
RMSE(test.MonthlyIncome_LR, mi.test$MonthlyIncome) / mean(mi.test$MonthlyIncome)
```

This model is performing well within the $3,000 goal, so moving on to...

## Random Forest

### Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     num = 5)

mi.fitRF <- train(MonthlyIncome ~ ., 
               data = mi.train, 
               method = "ranger", 
               importance = "impurity",
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100
               )
mi.fitRF
```

### Performance on Training Set

```{r}
summary(mi.fitRF)
plot(mi.fitRF)
```

```{r}
test.MonthlyIncome_RF <- predict(mi.fitRF, newdata = mi.test)
mi.fitRF.RMSE <- RMSE(test.MonthlyIncome_RF, mi.test$MonthlyIncome)
mi.fitRF.RMSE
RMSE(test.MonthlyIncome_RF, mi.test$MonthlyIncome) / mean(mi.test$MonthlyIncome)
```

### Min Depth Distribution

```{r}
mi.forest_frame <- min_depth_distribution(mi.fitRF$finalModel)
plot_min_depth_distribution(mi.forest_frame)
```

JobLevel has by far the most influence on MonthlyIncome, which makes sense given what we saw in the EDA. Really no surprises here.


### Mean minimal depth for most frequent interactions

```{r echo=F, warning=F, message=F}
plot_min_depth_interactions(mi.fitRF$finalModel, k=7)
```

Interaction between JobLevel and Age occurs most frequently in the random forest of trees.
It's interesting that JobRole Research Director and TotalWorkingYears interact moderately often and on average high up in their respective trees.

```{r echo=F, message=F}
multi_imps = measure_importance(mi.fitRF$finalModel)
plot_importance_ggpairs(multi_imps)
```

## Comparing MonthlyIncome Models

```{r}
mi.compare <- data.frame(model = c("Linear Regression", "Random Forest"), RMSE = c(mi.fitLR.RMSE, mi.fitRF.RMSE))
mi.compare
```

Both models perform well below the $3,000 RMSE threshold for this case study. Since Random Forest has slightly lower RMSE, Random Forest wins.


```{r}
mi.winner <- mi.fitRF
```


# Attrition

## KNN

For KNN, I'm optimizing for Kappa, which is more appropriate for imbalanced classes

```{r}
set.seed(12)
cv_control <- trainControl(
  method="repeatedcv",
  repeats = 3, 
  number = 5,
  classProbs = TRUE,
  savePredictions = TRUE,
  )

at.fitKNN <- train(Attrition ~ ., 
               data = at.train, 
               method = "knn", 
               metric = "Kappa",
               trControl = cv_control,
               preProcess = c("center","scale"),
#               tuneLength=20
               tuneGrid = expand.grid(k = c(1:5, 10, 20))
               )  
at.fitKNN
```

```{r}
plot(at.fitKNN)
confusionMatrix(at.fitKNN)
```

```{r}
at.fitKNN.predictions.raw <- predict(at.fitKNN, newdata = at.test, type="raw")
at.fitKNN.predictions.prob <- predict(at.fitKNN, newdata = at.test, type="prob")
confusionMatrix(at.fitKNN.predictions.raw, at.test$Attrition, positive="Yes")
```

```{r warning=F, message=F}
at.prediction.probabilities <- at.fitKNN.predictions.prob$Yes
at.predicted.classes <- at.fitKNN.predictions.raw
at.observed.classes <- at.test$Attrition

at.res.roc <- roc(at.observed.classes, at.prediction.probabilities)
plot.roc(at.res.roc, print.auc = TRUE, print.thres = "best")
```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
cutoff <- coords(at.res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
at.predicted.classes.balanced <- factor(
  ifelse( at.fitKNN.predictions.prob$Yes > cutoff, "Yes", "No"), levels=c("No","Yes"))
at.fitKNN.cm <- confusionMatrix(at.predicted.classes.balanced, at.test$Attrition, positive="Yes")
at.fitKNN.cm
```



# Random Forest

# Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     classProbs = TRUE,
                     savePredictions = TRUE,
                     summaryFunction = twoClassSummary,
                     num = 5)

rf_grid <- expand.grid(
  mtry = 4:10,
  splitrule = c("gini","extratrees", "hellinger"),
  min.node.size = c(1)
)

at.fitRF <- train(Attrition ~ ., 
               data = at.train, 
               method = "ranger", 
               metric = "ROC",
               importance = "impurity",
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100,
               tuneGrid=rf_grid)  
at.fitRF
```

# Performance on Training Set

```{r}
plot(at.fitRF)
confusionMatrix(at.fitRF)
```

## Min Depth Distribution

```{r}
at.forest_frame <- min_depth_distribution(at.fitRF$finalModel)
plot_min_depth_distribution(at.forest_frame)
```
Overtime is clearly the most influential variable on its own, but let's look at interactions...

### Mean minimal depth for most frequent interactions

```{r echo=F, warning=F, message=F}
plot_min_depth_interactions(at.fitRF$finalModel, k=7)
```

An interesting observation is that HourlyRate on its own is one of the less influential variables, but when combined with OverTimeYes, it becomes the most influential interaction. 

### Other measures of importance

```{r echo=F, message=F}
at.multi_imps = measure_importance(at.fitRF$finalModel)
plot_importance_ggpairs(at.multi_imps)
```

# Performance on Test Set

```{r}
at.fitRF.predictions.raw <- predict(at.fitRF, newdata = at.test, type="raw")
at.fitRF.predictions.prob <- predict(at.fitRF, newdata = at.test, type="prob")
confusionMatrix(at.fitRF.predictions.raw, at.test$Attrition, positive="Yes")
```

# ROC Curve and Optimal Cutoff

```{r warning=F, message=F}
at.prediction.probabilities <- at.fitRF.predictions.prob$Yes
at.predicted.classes <- at.fitRF.predictions.raw
at.observed.classes <- at.test$Attrition

# Compute roc
at.res.roc <- roc(at.observed.classes, at.prediction.probabilities)
plot.roc(at.res.roc, print.auc = TRUE, print.thres = "best")
```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
at.cutoff.randomforest <- coords(at.res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
at.predicted.classes.balanced <- factor(
  ifelse( at.fitRF.predictions.prob$Yes > at.cutoff.randomforest, "Yes", "No"), levels=c("No","Yes"))
at.fitRF.cm <- confusionMatrix(at.predicted.classes.balanced, at.test$Attrition, positive="Yes")
at.fitRF.cm
```


# Accuracy Model Comparison

```{r}
Model <- c("KNN", "Random Forest")
Accuracy <- c(at.fitKNN.cm$overall['Accuracy'], at.fitRF.cm$overall['Accuracy'])
Kappa <- c(at.fitKNN.cm$overall['Kappa'], at.fitRF.cm$overall['Kappa'])
Sensitivity <- c(at.fitKNN.cm$byClass['Sensitivity'], at.fitRF.cm$byClass['Sensitivity'])
Specificity <- c(at.fitKNN.cm$byClass['Specificity'], at.fitRF.cm$byClass['Specificity'])
at.compare <- data.frame(Model, Accuracy, Kappa, Sensitivity, Specificity)
at.compare
```

KNN is overall more accurate, but Random Forest has slightly higher Kappa and more Sensitivity, while being a bit less Specific. Also, KNN dipped below 60 on Sensitivity, so for the purposes of this case study, which requires both Sensitivity and Specificity to be more than 60, Random Forest wins.

```{r}
at.winner <- at.fitRF
at.winner.cutoff <- at.cutoff.randomforest
```


# Comp Set: No Attrition

## Load the No Attrition comp set and clean it the same way we did for modeling

```{r}
dfNoAttrition <- load.and.clean.for.attrition("doc/CaseStudy2CompSet No Attrition.csv", removeID = FALSE)
```

## Predict Attrition using our best model from the training above

```{r}
# Use the best model to get predicted probabilities for each class
dfNoAttrition.predictions.prob <- predict(at.winner, newdata = dfNoAttrition, type="prob")

# Use the most balanced cutoff on the predicted probabilities to get the Attrition values
dfNoAttrition.predictions.class <- factor(
  ifelse( dfNoAttrition.predictions.prob$Yes > at.winner.cutoff, "Yes", "No"), levels=c("No","Yes"))
```

## Save

```{r}
dfNoAttritionSubmission <- data.frame(ID = dfNoAttrition$ID, Attrition = dfNoAttrition.predictions.class)
write.csv(dfNoAttritionSubmission, "Case2PredictionsLichti Attrition.csv")
```

# Comp Set: No Salary

## Load the No Salary comp set and clean it the same way we did for modeling

```{r}
dfNoSalary <- load.and.clean.for.monthly_income("doc/CaseStudy2CompSet No Salary.csv", removeID = FALSE)
```

## Predict Salary

```{r}
dfNoSalary$MonthlyIncome <- predict(mi.winner, newdata = dfNoSalary)
```


## Save

```{r}
dfNoSalarySubmission <- data.frame(ID = dfNoSalary$ID, MonthlyIncome = dfNoSalary$MonthlyIncome)
write.csv(dfNoSalarySubmission, "Case2PredictionsLichti Salary.csv")
```


