---
title: "CaseStudy2DDS"
author: "Rinku Lichti"
date: "11/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Install and Load Libraries as needed
library(pacman)
p_load("summarytools", "dplyr", "ggplot2", "ggsci", "caret", "corrplot", "GGally", "pROC", "readr")
```

# Load the data

```{r  eruptions, echo=FALSE}
df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
```

# Summarize the raw data

```{r}
print(dfSummary(df, graph.magnif = 0.75), method = 'browser')
```

```{r}
clean.for.eda <- function(dirty) {
  dfTemp <- dirty
  
  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp <- dfTemp %>% relocate(Attrition, .after = last_col())

  dfTemp
}

df <- clean.for.eda(df)
```


```{r}
str(df)
```

# Visualize Attrition

## Attrition Distribution

```{r}
table(df$Attrition)
```

Attrition records represent a small minority of the people represented in this data.

## Attrition Bar Plot By Age

```{r}
ggplot(df) + 
  geom_histogram(mapping = aes(x=Age, fill=Attrition)) + 
  ggtitle("Distribution of Attrition by Age") + 
  scale_fill_jco() +
  ggtitle("Attrition by Age")
```

```{r}
# Helper function to plot attrition rate by anything...
plot_attrition_rate_by <- function(data, column) {
  dfTemp <- data %>%
  group_by_(column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}
```



```{r warning=F, message=F}
plot_attrition_rate_by(df, "Age")
```

```{r}
df.age_eda <- df %>%
  group_by(age_group) %>%
  count(Attrition) %>%
  mutate(age_group_attr = n/sum(n)) %>%
  filter(Attrition == "Yes")

ggplot(df.age_eda, aes(x=age_group, y=age_group_attr, group=1)) +
  geom_line(size=1) +
  geom_point(size=2) + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Attrition Rate by Age Group") + 
  ylab("Attrition Rate")
```

## DistanceFromHome

```{r warning=F, message=F}
plot_attrition_rate_by(df, "DistanceFromHome")
```
## JobSatisfaction

```{r  warning=F, message=F}
plot_attrition_rate_by(df, "JobSatisfaction")
```

## JobLevel

```{r warning=F, message=F}
plot_attrition_rate_by(df, "JobLevel")
```
## JobInvolvement

```{r warning=F, message=F}
plot_attrition_rate_by(df, "JobInvolvement")
```

## NumCompaniesWorked

```{r warning=F, message=F}
plot_attrition_rate_by(df, "NumCompaniesWorked")
```

## PercentSalaryHike

```{r warning=F, message=F}
plot_attrition_rate_by(df, "PercentSalaryHike")
```
## TrainingTimesLastYear

```{r warning=F, message=F}
plot_attrition_rate_by(df, "TrainingTimesLastYear")
```

## WorkLifeBalance

```{r warning=F, message=F}
plot_attrition_rate_by(df, "WorkLifeBalance")
```

## YearsAtCompany

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsAtCompany")
```
## YearsInCurrentRole

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsInCurrentRole")
```

## YearsSinceLastPromotion

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsSinceLastPromotion")
```
## YearsWithCurrManager

```{r warning=F, message=F}
plot_attrition_rate_by(df, "YearsWithCurrManager")
```

## JobRole

```{r warning=F, message=F}
plot_attrition_rate_hbar_by <- function(data, column) {
  dfTemp <- data %>%
    group_by_(column) %>%
    count(Attrition) %>%
    mutate(AttritionRate = n/sum(n)) %>%
    filter(Attrition == "Yes")
  dfTemp <- dfTemp %>%
    arrange(desc(AttritionRate))

  ggplot(dfTemp, aes_string(x=paste0("reorder(",column,", AttritionRate)"), y="AttritionRate")) +
    geom_col() +
    coord_flip() + 
    scale_color_jco() +
    scale_fill_jco() +
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}


plot_attrition_rate_hbar_by(df, "JobRole")
```

```{r}
dfTemp <- df
dfTemp$JobSatisfactionF = as.factor(df$JobSatisfaction)

dfTemp <- dfTemp %>%
    group_by(JobRole) %>%
    count(JobSatisfaction) %>%
    mutate(JobSatisfactionPerc = n/sum(n))

ggplot(dfTemp, aes(fill=as.factor(JobSatisfaction), y=JobSatisfactionPerc, x=JobRole)) + 
  geom_bar(position="dodge", stat="identity") + 
  coord_flip() + 
  scale_color_jco() +
  scale_fill_jco() +
  ggtitle("Job Satisfaction as a % of people in each Job Role")
```



## JobRole by Age

```{r warning=F, message=F}
plot_attrition_rate_and_facet_by <- function(data, column, facet_column) {
  dfTemp <- data %>%
  group_by_(column, facet_column) %>%
  count(Attrition) %>%
  mutate(AttritionRate = n/sum(n)) %>%
  filter(Attrition == "Yes")

  ggplot(dfTemp, aes_string(x=column, y="AttritionRate", group=1)) +
    geom_line(size=1) +
    geom_smooth() + 
    geom_point(size=2) + 
    scale_color_jco() +
    scale_fill_jco() +
    facet_wrap(facet_column) + 
    ggtitle(paste("Attrition Rate by", column)) + 
    ylab("Attrition Rate")
}

plot_attrition_rate_and_facet_by(df, "Age", "JobRole")
```

# Checking for correlation

```{r warning=F, message=F}
# Look for high correlation

# Only look at numeric fields, and omit ones with constant values
df <- df %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount, -ID))
df.numeric <- df[, sapply(df, is.numeric)]
df.without_na <- na.omit(df.numeric)

corrs = cor(df.without_na) # Calculate correlations between all variables
high_corrs = findCorrelation(corrs, cutoff=0.5)
corrs = cor(df.without_na[,high_corrs]) # get a data frame with only highly correlated variables

#Create corrplot for numeric variables
corrplot(corrs)
```

```{r warning=F, message=F}
ggpairs(df.without_na[,high_corrs])
```

# Identify the top factors contributing to turnover

```{r}
set.seed(1234)
RFcontrol <- rfeControl(
  functions=rfFuncs, 
  method="cv", 
  number=5, 
  verbose = FALSE)

sizes <- c(1:5, 10, 15, 20)

RFresults <- rfe(df[,1:(ncol(df)-1)], 
                 df[[ncol(df)]], 
                 sizes=sizes, 
                 rfeControl=RFcontrol)

RFresults
varImp(RFresults)
```

The Top factors that contribute to turnover are:
1. OverTime
...


# Clean/Train/Test Split

```{r}
clean.for.modeling <- function(dirty) {
  dfTemp <- dirty %>% dplyr::select(c(-StandardHours, -Over18, -EmployeeCount))

  dfTemp$age_group <- cut(dfTemp$Age, 
      breaks = c(17,22,26,30,34,38,42,46,50,Inf), 
      labels = c("18-22", "22-26", "26-30", "30-34", "34-38", "38-42", "42-46", "46-50", "50+"))

  dfTemp
}

df <- read.csv("doc/CaseStudy2-data.csv", stringsAsFactors=TRUE)
df <- clean.for.modeling(df)

df <- df %>% dplyr::select(c(-ID))
df <- df %>% relocate(Attrition, .after = last_col())

set.seed(1234)
num_rows <- nrow(df)
train_idx <- sample(1:num_rows, 0.8 * num_rows)
test_idx <- setdiff(1:num_rows, train_idx)
train <- df[train_idx, ]
test <- df[test_idx, ]
```


# MonthlyIncome

# Random Forest

# Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     num = 5)

fitRF.MonthlyIncome <- train(MonthlyIncome ~ ., 
               data = train, 
               method = "ranger", 
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100
               )
fitRF.MonthlyIncome
```

# Performance on Training Set

```{r}
summary(fitRF.MonthlyIncome)
plot(fitRF.MonthlyIncome)
```

```{r}
test.MonthlyIncome_RF <- predict(fitRF.MonthlyIncome, newdata = test)
RMSE(test.MonthlyIncome_RF, test$MonthlyIncome)
RMSE(test.MonthlyIncome_RF, test$MonthlyIncome) / mean(test$MonthlyIncome)
```


# Attrition ------

# KNN

For KNN, I'm optimizing for Kappa, which is more appropriate for imbalanced classes

```{r}
set.seed(12)
cv_control <- trainControl(
  method="repeatedcv",
  repeats = 3, 
  number = 5,
  classProbs = TRUE,
  savePredictions = TRUE,
#  summaryFunction = twoClassSummary
  )

fitKNN <- train(Attrition ~ ., 
               data = train, 
               method = "knn", 
               metric = "Kappa",
               trControl = cv_control,
               preProcess = c("center","scale"),
#               tuneLength=20
               tuneGrid = expand.grid(k = c(1:5, 10, 20))
               )  
fitKNN
```

```{r}
plot(fitKNN)
confusionMatrix(fitKNN)
```

```{r}
fitKNN.predictions.raw <- predict(fitKNN, newdata = test, type="raw")
fitKNN.predictions.prob <- predict(fitKNN, newdata = test, type="prob")
confusionMatrix(fitKNN.predictions.raw, test$Attrition, positive="Yes")
```

```{r warning=F, message=F}
prediction.probabilities <- fitKNN.predictions.prob$Yes
predicted.classes <- fitKNN.predictions.raw
observed.classes <- test$Attrition

res.roc <- roc(observed.classes, prediction.probabilities)
plot.roc(res.roc, print.auc = TRUE, print.thres = "best")
```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
cutoff <- coords(res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
predicted.classes.balanced <- factor(
  ifelse( fitKNN.predictions.prob$Yes > cutoff, "Yes", "No"), levels=c("No","Yes"))
confusionMatrix(predicted.classes.balanced, test$Attrition, positive="Yes")
```



# Random Forest

# Train a Random Forest, tuning mtry and splitrule

```{r}
set.seed(12)
cv_control <- trainControl(method="cv", 
                     classProbs = TRUE,
                     savePredictions = TRUE,
                     summaryFunction = twoClassSummary,
                     num = 5)

rf_grid <- expand.grid(
  mtry = 4:8,
  splitrule = c("gini","extratrees", "hellinger"),
  min.node.size = c(1)
)

fitRF <- train(Attrition ~ ., 
               data = train, 
               method = "ranger", 
               metric = "ROC",
               trControl = cv_control,
               num.threads = 6,
               num.trees = 100,
               tuneGrid=rf_grid)  
fitRF
```

# Performance on Training Set

```{r}
plot(fitRF)
confusionMatrix(fitRF)
```

# Performance on Test Set

```{r}
fitRF.predictions.raw <- predict(fitRF, newdata = test, type="raw")
fitRF.predictions.prob <- predict(fitRF, newdata = test, type="prob")
confusionMatrix(fitRF.predictions.raw, test$Attrition, positive="Yes")
```


# ROC Curve and Optimal Cutoff

```{r warning=F, message=F}
prediction.probabilities <- fitRF.predictions.prob$Yes
predicted.classes <- fitRF.predictions.raw
observed.classes <- test$Attrition

# Compute roc
res.roc <- roc(observed.classes, prediction.probabilities)
plot.roc(res.roc, print.auc = TRUE, print.thres = "best")

# If we wanted cutoffs for specific specificities we specifically specify, we could do THIS:
#roc.data <- data_frame(
#  thresholds = res.roc$thresholds,
#  sensitivity = res.roc$sensitivities,
#  specificity = res.roc$specificities
#)
# Then we can get the cutoff for specificity = <something> like this
#roc.data %>% filter(specificity >= 0.6)
#...or similar

```

```{r}
# Get the best cutoff for balancing Sensitivity and Specificity
cutoff.randomforest <- coords(res.roc, "best", ret="threshold", transpose = FALSE)$threshold

# Predict using the best cutoff and confirm with a Confusion Matrix
predicted.classes.balanced <- factor(
  ifelse( fitRF.predictions.prob$Yes > cutoff.randomforest, "Yes", "No"), levels=c("No","Yes"))
confusionMatrix(predicted.classes.balanced, test$Attrition, positive="Yes")
```


# Model Comparison


# Comp Set: No Attrition

## Load the No Attrition comp set and clean it the same way we did for modeling

```{r}
dfNoAttrition <- read.csv("doc/CaseStudy2CompSet No Attrition.csv", stringsAsFactors=TRUE)
dfNoAttrition <- clean.for.modeling(dfNoAttrition)
```

## Predict Attrition using our best model from the training above

```{r}
# Use the best model to get predicted probabilities for each class
dfNoAttrition.predictions.prob <- predict(fitRF, newdata = dfNoAttrition, type="prob")

# Use the most balanced cutoff on the predicted probabilities to get the Attrition values
dfNoAttrition.predictions.class <- factor(
  ifelse( dfNoAttrition.predictions.prob$Yes > cutoff.randomforest, "Yes", "No"), levels=c("No","Yes"))
```

## Save

```{r}
dfNoAttritionSubmission <- data.frame(ID = dfNoAttrition$ID, Attrition = dfNoAttrition.predictions.class)
write.csv(dfNoAttritionSubmission, "Case2PredictionsLichti Attrition.csv")
```

# Comp Set: No Salary

## Load the No Salary comp set and clean it the same way we did for modeling

```{r}
dfNoSalary <- read.csv("doc/CaseStudy2CompSet No Salary.csv", stringsAsFactors=TRUE)
dfNoSalary <- clean.for.modeling(dfNoSalary)
```

## Predict Salary

```{r}
dfNoSalary$MonthlyIncome <- predict(fitRF.MonthlyIncome, newdata = dfNoSalary)
```


## Save

```{r}
dfNoSalarySubmission <- data.frame(ID = dfNoSalary$ID, MonthlyIncome = dfNoSalary$MonthlyIncome)
write.csv(dfNoSalarySubmission, "Case2PredictionsLichti Salary.csv")
```


